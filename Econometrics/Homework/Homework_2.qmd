---
format: 
  pdf:
    geometry:
      - top=20mm
      - left=20mm
      - heightrounded
    fontsize: 12pt
    documentclass: scrartcl
    papersize: a4
    toccolor: black
echo: true
warning: false
bibliography: documentobjects/texstuff/references.bib
csl: documentobjects/texstuff/apa.csl
header-includes:
  - \usepackage{wrapfig}
  - \usepackage{subcaption}
  - \usepackage{amsmath}
  - \usepackage{cancel}
  - \usepackage{hyperref}
  - \usepackage{tikz}
  - \usepackage{tabularx}
  - \usepackage{colortbl}
  - \usepackage{xcolor}
  - \renewcommand{\maketitle}{}
  - \definecolor{cornflowerblue}{RGB}{100,149,237}
  - \definecolor{darkgrey}{RGB}{220,220,220}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhf{} 
  - \fancyhead[L]{\rightmark}
  - \fancyhead[R]{\thepage}
  - \fancyfoot[C]{\thepage}
nocite: |
  @*
---

\newgeometry{left=0cm, right=0cm, top=0cm, bottom=0cm}
\vspace*{0.5cm}
\begin{flushleft}
    \vspace*{0.5cm}
    \hspace*{2.5cm}{\color{black}\fontsize{11}{13.2}\selectfont Waseda University \\[0.2em]
    \hspace*{2.5cm}\color{black}\fontsize{8}{13.2}\selectfont School of Political Science and Economics \\[0.2em]
    \hspace*{2.5cm}\large{\color{black}\textbf{Homework 2}}  \\[0.5em]
\hspace*{2.5cm}\color{black}\fontsize{11}{13.2}\selectfont Daniel Fabio Groth \\[0.5em]
    \hspace*{2.5cm}\color{black}\fontsize{11}{13.2}\selectfont Econometrics, Fall 2024 \\[0.5em]
    \hspace*{2.0cm}
    \par}
\end{flushleft} 
\restoregeometry
\tableofcontents
\newpage

```{r, include=FALSE}
library(extraDistr)
library(tidyverse)
```

# **Problem 1**

Solve excercise 1,3 and 5 in Problem set 2.

## **Excercise 1:** Show the following equalities hold:


$$\frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X_n})^2 = \frac{1}{n} \sum_{i=1}^{n} X_i(X_i - \bar{X}_n) \tag {1}$$


Let's start by looking at the left side of the equation:

$$ \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X}_n)^2 \rightarrow (X_i - \hat{X}_n)^2  \tag {1.1} $$ 

Then we can expand the equation:

$$ (X_i - \bar{X}_n)^2 = X_i^2 - 2X_i\bar{X}_n + \bar{X}_n^2 \tag {1.2} $$

thus, we can rewrite the equation as:

$$ \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X})_n^2 = \frac{1}{n} \sum_{i=1}^{n} X_i^2 - 2X_i\bar{X}_n + \bar{X}_n^2 \tag {1.3} $$ 

Then we separate the terms:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i^2 - \frac{2 \bar{X}_n}{n} \sum_{i=1}^{n} X_i+ \frac{\bar{X}_n^2}{n} \sum_{i=1}^{n} 1 \tag {1.4} $$

Then since $\sum_{i=1}^{n} X_i = n\bar{X}_n$, and $\sum_{i=1}^{n} 1 = n$, this just becomes:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i^2 - 2\bar{X}_n \bar{X}_n + \bar{X}_n^2 = \frac{1}{n} \sum_{i=1}^{n} X_i^2 - \bar{X}_n^2 \tag {1.5} $$ 

Now we can look at the right side of the equation:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i(X_i - \bar{X}_n) \rightarrow X_i(X_i - \bar{X}_n) \tag {1.6} $$ 

Then we can expand the equation:

$$ X_i(X_i - \bar{X}_n) = X_i^2 - X_i\bar{X}_n \tag {1.7} $$

thus, we can rewrite the equation as:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i(X_i - \bar{X}_n) = \frac{1}{n} \sum_{i=1}^{n} X_i^2 - \frac{\bar{X}_n}{n} \sum_{i=1}^{n} X_i \tag {1.8} $$ 
Then we can use the same logic as before:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i^2 - \bar{X}_n \bar{X_n} = \frac{1}{n} \sum_{i=1}^{n} X_i^2 - \bar{X}_n^2 \tag {1.9} $$ 

Thus, we have shown that the left side of the equation is equal to the right side of the equation.

$$\frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X_n})^2 = \frac{1}{n} \sum_{i=1}^{n} X_i(X_i - \bar{X}_n) \tag {1}$$

## Excersice 1 cont: Showing that the second equality holds:


$$\frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X}_n)(Y_i-\bar{Y}_n) = \frac{1}{n} \sum_{i=1}^{n} X_i (Y_i - \bar{Y}_n) = \frac{1}{n} \sum_{i=1}^{n} Y_i (X_i - \bar{X}_n) \tag {2}$$

Let's start by looking at the left side of the equation:

$$ \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X}_n)(Y_i-\bar{Y}_n) \rightarrow (X_i - \bar{X}_n)(Y_i-\bar{Y}_n)  \tag {2.1} $$ 

Then we can expand the equation:

$$ (X_i - \bar{X}_n)(Y_i-\bar{Y}_n) = X_iY_i - X_i\bar{Y}_n - \bar{X}_nY_i + \bar{X}_n\bar{Y}_n \tag {2.2} $$

thus, we can rewrite the equation as:

$$ \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X}_n)(Y_i-\bar{Y}_n) = \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \frac{1}{n} \sum_{i=1}^{n} X_i\bar{Y}_n - \frac{1}{n} \sum_{i=1}^{n} \bar{X}_nY_i + \frac{1}{n} \sum_{i=1}^{n} \bar{X}_n\bar{Y}_n \tag {2.3} $$ 

Then we separate the terms:

$$ \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \frac{1}{n} \bar{Y}_n \sum_{i=1}^{n} X_i - \frac{1}{n} \bar{X}_n \sum_{i=1}^{n} Y_i + \frac{1}{n} \bar{X}_n \bar{Y}_n \sum_{i=1}^{n} 1 \tag {2.4} $$

Then since $\sum_{i=1}^{n} X_i = n\bar{X}_n$, $\sum_{i=1}^{n} Y_i = n\bar{Y}_n$, and $\sum_{i=1}^{n} 1 = n$, this just becomes:

$$ \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \bar{Y}_n \bar{X}_n - \bar{X}_n \bar{Y}_n + \bar{X}_n \bar{Y}_n = \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \bar{X}_n \bar{Y}_n \tag {2.5} $$

Let's now look at the middle term of the equation:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i (Y_i - \bar{Y}_n) \rightarrow X_i (Y_i - \bar{Y}_n) \tag {2.6} $$ 

Then we can expand the equation:

$$ X_i (Y_i - \bar{Y}_n) = X_iY_i - X_i\bar{Y}_n \tag {2.7} $$

thus, we can rewrite the equation as:

$$ \frac{1}{n} \sum_{i=1}^{n} X_i (Y_i - \bar{Y}_n) = \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \frac{\bar{Y}_n}{n} \sum_{i=1}^{n} X_i \tag {2.8} $$ 

Then we can use the same logic as before:

$$ \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \frac{\bar{Y}_n}{n} \sum_{i=1}^{n} X_i = \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \bar{X}_n \bar{Y}_n \tag {2.9} $$
Finally looking at the right side of the equation:

$$ \frac{1}{n} \sum_{i=1}^{n} Y_i (X_i - \bar{X}_n) \rightarrow Y_i (X_i - \bar{X}_n) \tag {2.10} $$ 

Then we can expand the equation:

$$ Y_i (X_i - \bar{X}_n) = X_iY_i - Y_i\bar{X}_n \tag {2.11} $$

thus, we can rewrite the equation as:

$$ \frac{1}{n} \sum_{i=1}^{n} Y_i (X_i - \bar{X}_n) = \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \frac{\bar{X}_n}{n} \sum_{i=1}^{n} Y_i \tag {2.12} $$ 

Then using same logic and substituting:

$$ \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \frac{\bar{X}_n}{n} \sum_{i=1}^{n} Y_i = \frac{1}{n} \sum_{i=1}^{n} X_iY_i - \bar{X}_n \bar{Y}_n \tag {2.13} $$

Finally, we can see that equation (2.5), (2.9), and (2.13) are all equal to each other, thus we have shown that:

$$ \frac{1}{n} \sum_{i=1}^{n} (X_i - \bar{X}_n)(Y_i-\bar{Y}_n) = \frac{1}{n} \sum_{i=1}^{n} X_i (Y_i - \bar{Y}_n) = \frac{1}{n} \sum_{i=1}^{n} Y_i (X_i - \bar{X}_n) \tag {2.14} $$

\newpage


## **Excercise 3**

Consider a regression model that has no intercept term:

$$ Y_i = X_i \beta_1 + \epsilon_i = 1 ,...,n. $$ Derive the least squares estimator for $\beta_1$.

## **Excercise 5**

Let ($\hat{\beta}_0, \hat{\beta}_1$) be the ordinary least squares estimator of

$$ Y_i = \beta_0 + X_i \beta_1  + \epsilon_i, i = 1,...,n. $$

The prediction error (i.e, residual) for each i is given by $\hat{e_i} = Y_i - \hat{\beta}_0n - X_i \hat{\beta}_1n$. Show that the sum of the residuals is zero, i.e, $\sum_{i=1}^{n} \hat{e_i} = 0$.

\newpage

# **Problem 2**

Show that under Assumptions 1-3 in the L.6 slides, the variance of $\hat{\beta}_{n1}$ is given by $X_1,....,X_n$ is given by:

$$ \frac{\sigma^2}{n} = \frac{1}{\frac{1}{n}\sum_{i=1}^{n} (X_i - \bar{X}_n)^2} $$ Proof:

\newpage

# **Problem 3**

In this problem, you calculate the OLS estimators using R. Please obtain your own data by using the following code:

```{r}
set.seed(34)

data <- as.data.frame(state.x77)
data <- data[sample(1:50, 40),]
```

where you need to input the last two digits of your student number for A. Here we use the information of the life expectancy as Y and the illiteracy rate as X. Then answer the following problems.

1)  We consider the following two models.

**Model 1:** $Y_i = \beta_0 + X_i \beta_1 + \epsilon_i$

**Model 2:** $Y_i =  X_i\beta_1 + \epsilon_i$

Obtain the OLS estimators for these two models **without using the lm() function** and compare the results with those given by the lm function.

2)  For the two models, visually compare the distribution of the data and the lines obtained by OLS as we did in p.16 in the Lecture 6 slides. Discuss which results look more reasonable

3)  Based on the "more reasonable" model you chose, explain what the estimated value of $\beta_1$ implies about the relationship between the illiteracy rate and the life expectancy.

\newpage

# Usage of AI

## Copilot

As I am writing this document in Rstudio, there is an integration of copilot which sometimes automatically suggests code snippets. Sometimes it works great and my latex math gets written perfectly, and other times it just gives me a bunch of random unrelevant latex math or code.

Here is a [Link to copilot](https://copilot.microsoft.com/).

## ChatGPT

Here is the link to the conversation where I asked questions:
